"""Neural Ensemble Framework"Main ensemble framework combining all neural models for comprehensivetrading signal generation with GaryTaleb integration."""import torchimport torch.nn as nnimport numpy as npimport pandas as pdfrom typing import Dict, List, Tuple, Optional, Any, Union, Callablefrom dataclasses import dataclassimport timefrom concurrent.futures import ThreadPoolExecutor, as_completedimport threadingfrom collections import deque# Import individual modelsfrom ..lstm.lstm_predictor import LSTMPredictor, create_lstm_predictorfrom ..transformer.sentiment_analyzer import FinancialSentimentAnalyzer, create_sentiment_analyzerfrom ..cnn.pattern_recognizer import ChartPatternCNN, create_pattern_recognizerfrom ..rl.strategy_optimizer import StrategyOptimizerRL, create_strategy_optimizer@dataclassclass EnsembleConfig:        """Configuration for neural ensemble."""    # Model weights        lstm_weight: float = 0.30        transformer_weight: float = 0.25        cnn_weight: float = 0.25        rl_weight: float = 0.20    # Ensemble strategy        strategy: str = 'weighted_voting'  # 'voting', 'weighted_voting', 'blending', 'stacking'    # GaryxTaleb integration        gary_dpi_ensemble_weight: float = 0.35        taleb_antifragile_ensemble_weight: float = 0.25        volatility_adaptive_weighting: bool = True    # Performance optimization        parallel_inference: bool = True        max_workers: int = 4        cache_predictions: bool = True        cache_size: int = 1000    # Target performance        target_ensemble_inference_ms: float = 90.0        confidence_threshold: float = 0.65        signal_aggregation_method: str = 'weighted_average'  # 'average', 'weighted_average', 'majority_vote'    # Real-time adaptation        adaptive_weights: bool = True        performance_window: int = 100        weight_adaptation_rate: float = 0.05class ModelPrediction:        """Container for individual model predictions."""    def __init__(self,
        model_name: str,        prediction: Union[np.ndarray, Dict[str, Any]],        confidence: float,        inference_time_ms: float,        model_specific_data: Optional[Dict[str, Any]] = None):            """Initialize model prediction."        Args:
                model_name: Name of the model                prediction: Model prediction (format varies by model)                confidence: Prediction confidence [0, 1]                inference_time_ms: Inference time in milliseconds                model_specific_data: Additional model-specific data                """                self.model_name = model_name                self.prediction = prediction                self.confidence = confidence                self.inference_time_ms = inference_time_ms                self.model_specific_data = model_specific_data or {}                self.timestamp = time.time()    def to_dict(self) -> Dict[str, Any]:
            """Convert to dictionary representation."""        return {
        'model_name': self.model_name,
        'prediction': self.prediction,
        'confidence': self.confidence,
        'inference_time_ms': self.inference_time_ms,
        'model_specific_data': self.model_specific_data,
        'timestamp': self.timestamp}
class NeuralEnsemble:        """Neural ensemble for comprehensive trading signal generation."        Combines:            - LSTM: Price prediction with attention            - Transformer: Sentiment analysis            - CNN: Chart pattern recognition            - RL: Strategy optimization            Features:                - GaryTaleb integration across all models                - Parallel inference for speed                - Adaptive model weighting                - Multiple ensemble strategies                - Real-time performance optimization                """    def __init__(self, config: EnsembleConfig):
            """Initialize neural ensemble."        Args:
                config: Ensemble configuration                """                self.config = config                self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')        # Initialize individual models                self.models = {}                self.model_weights = {}                self.model_performance_history = {}        # Performance tracking                self.ensemble_inference_times = deque(maxlen=1000)                self.prediction_cache = {} if config.cache_predictions else None                self.cache_lock = threading.Lock() if config.cache_predictions else None        # Adaptive weighting system                self.adaptive_weights = {                'lstm': config.lstm_weight,                'transformer': config.transformer_weight,                'cnn': config.cnn_weight,                'rl': config.rl_weight}        # Performance tracking for adaptation                self.model_performance_scores = {                'lstm': deque(maxlen=config.performance_window),                'transformer': deque(maxlen=config.performance_window),                'cnn': deque(maxlen=config.performance_window),                'rl': deque(maxlen=config.performance_window)                }        # GaryxTaleb ensemble state                self.gary_dpi_ensemble_factors = {                'momentum_consensus': 0.0,                'volume_confirmation': 0.0,                'technical_alignment': 0.0,                'pattern_confirmation': 0.0}                self.taleb_antifragile_ensemble_factors = {                'volatility_opportunity': 0.0,                'asymmetric_payoff': 0.0,                'model_consensus_uncertainty': 0.0,                'tail_risk_assessment': 0.0)        # Thread pool for parallel inference                if config.parallel_inference:                    self.executor = ThreadPoolExecutor(max_workers=config.max_workers)                else:                        self.executor = None    def initialize_models(self,
        market_data: Optional[pd.DataFrame] = None,        model_configs: Optional[Dict[str, Any]] = None) -> Dict[str, bool]:            """Initialize all individual models."        Args:
                market_data: Market data for RL training                model_configs: Custom configurations for each model                Returns:                    Dictionary indicating successful initialization of each model                    """                    model_configs = model_configs or {}                    initialization_results = {}                    try:        # Initialize LSTM predictor
                    pass  # Auto-fixed: empty block                    pass  # Auto-fixed: empty block                    pass  # Auto-fixed: empty block                    pass  # Auto-fixed: empty block                    pass  # Auto-fixed: empty block                    lstm_config = model_configs.get('lstm', {})                    self.models['lstm'] = create_lstm_predictor(                    sequence_length=lstm_config.get('sequence_length', 60),                    hidden_size=lstm_config.get('hidden_size', 128),                    enable_dpi=True,                    antifragility_weight=0.15                    )                    initialization_results['lstm'] = True                except Exception as e:                        print(f\"Failed to initialize LSTM: {e)\")                        initialization_results['lstm'] = False                        try:        # Initialize Sentiment Analyzer
                        pass  # Auto-fixed: empty block                        pass  # Auto-fixed: empty block                        pass  # Auto-fixed: empty block                        pass  # Auto-fixed: empty block                        pass  # Auto-fixed: empty block                        sentiment_config = model_configs.get('sentiment', {})                        self.models['transformer'] = create_sentiment_analyzer(                        max_length=sentiment_config.get('max_length', 256),                        enable_caching=True,                        dpi_integration=True,                        antifragile_enhancement=True                        )                        initialization_results['transformer'] = True                    except Exception as e:                            print(f\"Failed to initialize Sentiment Analyzer: {e)\")                            initialization_results['transformer'] = False                            try:        # Initialize Chart Pattern CNN
                            pass  # Auto-fixed: empty block                            pass  # Auto-fixed: empty block                            pass  # Auto-fixed: empty block                            pass  # Auto-fixed: empty block                            pass  # Auto-fixed: empty block                            cnn_config = model_configs.get('cnn', {})                            self.models['cnn'] = create_pattern_recognizer(                            image_size=cnn_config.get('image_size', (224, 224)),                            confidence_threshold=0.7,                            enable_dpi=True,                            enable_antifragile=True,                            fast_mode=True                            )                            initialization_results['cnn'] = True                        except Exception as e:                                print(f\"Failed to initialize Chart Pattern CNN: {e)\")                                initialization_results['cnn'] = False                                try:        # Initialize RL Strategy Optimizer
                                pass  # Auto-fixed: empty block                                pass  # Auto-fixed: empty block                                pass  # Auto-fixed: empty block                                pass  # Auto-fixed: empty block                                pass  # Auto-fixed: empty block                                if market_data is not None:                                    rl_config = model_configs.get('rl', {})                                    self.models['rl'] = create_strategy_optimizer(                                    market_data=market_data,                                    initial_capital=rl_config.get('initial_capital', 200.0),                                    algorithm='ppo',                                    enable_gary_dpi=True,                                    enable_taleb_antifragile=True,                                    fast_inference=True                                    )                                    initialization_results['rl'] = True                                else:                                        print(\"Market data required for RL initialization\")                                        initialization_results['rl'] = False                                    except Exception as e:                                            print(f\"Failed to initialize RL Strategy Optimizer: {e)\")                                            initialization_results['rl'] = False        # Update model weights based on successful initialization                                            active_models = [k for k, v in initialization_results.items() if v]                                            if active_models:                                                self._rebalance_weights(active_models)                                                print(f\"Ensemble initialized with {len(active_models)} models: {active_models)\")                                                return initialization_results    def predict(self,
        ohlcv_data: np.ndarray,        text_data: Optional[List[str]] = None,        market_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:            """Generate comprehensive trading signal from ensemble."        Args:
                ohlcv_data: OHLCV market data [seq_len, 5]                text_data: Optional text data for sentiment analysis                market_context: Additional market context                Returns:                    Comprehensive ensemble prediction with all model outputs                    """                    start_time = time.time()        # Check prediction cache                    cache_key = None                    if self.prediction_cache is not None:                        cache_key = self._generate_cache_key(ohlcv_data, text_data, market_context)                        with self.cache_lock:                            if cache_key in self.prediction_cache:                                cached_result = self.prediction_cache[cache_key].copy()                                cached_result['from_cache'] = True                                cached_result['total_inference_time_ms'] = (time.time() - start_time) * 1000                                return cached_result        # Prepare model inputs                                model_inputs = self._prepare_model_inputs(ohlcv_data, text_data, market_context)        # Get predictions from all models                                if self.config.parallel_inference and self.executor:                                    model_predictions = self._get_parallel_predictions(model_inputs)                                else:                                        model_predictions = self._get_sequential_predictions(model_inputs)        # Apply ensemble strategy                                        ensemble_prediction = self._apply_ensemble_strategy(model_predictions)        # Gary's DPI ensemble analysis'                                        gary_dpi_analysis = self._analyze_gary_dpi_ensemble(model_predictions, ensemble_prediction)        # Taleb's antifragility ensemble assessment'                                        taleb_analysis = self._analyze_taleb_antifragile_ensemble(model_predictions, ensemble_prediction)        # Generate final trading signal                                        final_signal = self._generate_ensemble_trading_signal(                                        ensemble_prediction, gary_dpi_analysis, taleb_analysis                                        )        # Track performance for adaptive weighting                                        self._update_model_performance(model_predictions)        # Calculate total inference time                                        total_inference_time = (time.time() - start_time) * 1000                                        self.ensemble_inference_times.append(total_inference_time)        # Compile final result                                        result = {                                        'ensemble_prediction': ensemble_prediction,                                        'individual_predictions': {k: v.to_dict() for k, v in model_predictions.items()},                                        'gary_dpi_ensemble_analysis': gary_dpi_analysis,                                        'taleb_antifragile_ensemble_analysis': taleb_analysis,                                        'final_trading_signal': final_signal,                                        'model_weights_used': self.adaptive_weights.copy(),                                        'total_inference_time_ms': total_inference_time,                                        'target_met': total_inference_time < self.config.target_ensemble_inference_ms,                                        'active_models': list(model_predictions.keys()),                                        'ensemble_confidence': self._calculate_ensemble_confidence(model_predictions),                                        'consensus_strength': self._calculate_consensus_strength(model_predictions),                                        'from_cache': False)        # Update cache                                        if self.prediction_cache is not None and len(self.prediction_cache) < self.config.cache_size:                                            with self.cache_lock:                                                self.prediction_cache[cache_key] = result.copy()        # Adaptive weight updates                                                if self.config.adaptive_weights:                                                    self._update_adaptive_weights()                                                    return result    def _prepare_model_inputs(self,
