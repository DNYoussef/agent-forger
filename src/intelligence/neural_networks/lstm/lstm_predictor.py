"""LSTM Predictor for Financial Time Series"2-layer LSTM with attention mechanism for price prediction.Integrates with Gary's DPI calculations and supports <100ms inference.'"""import torchimport torch.nn as nnimport numpy as npfrom typing import Dict, List, Tuple, Optional, Anyimport timefrom dataclasses import dataclassfrom .attention_mechanism import AttentionLayer, TemporalAttention, FinancialAttention@dataclassclass LSTMConfig:        """Configuration for LSTM predictor."""        input_size: int = 5  # OHLCV features        hidden_size: int = 128        num_layers: int = 2        dropout: float = 0.2        sequence_length: int = 60  # 1 hour of minute data        prediction_horizon: int = 5  # Predict 5 minutes ahead        attention_heads: int = 8        batch_size: int = 32        learning_rate: float = 0.001        weight_decay: float = 1e-4    # GaryxTaleb integration        antifragility_weight: float = 0.15  # Taleb's antifragility factor'        dpi_integration: bool = True  # Gary's DPI calculations'        volatility_scaling: bool = True  # Dynamic volatility adjustmentclass LSTMPredictor(nn.Module):        """2-Layer LSTM with attention for financial time series prediction."        Optimized for <100ms inference with GaryTaleb integration.        Supports antifragility principles and DPI calculations.        """    def __init__(self, config: LSTMConfig):
            """Initialize LSTM predictor."        Args:
                config: LSTM configuration parameters                """                super(LSTMPredictor, self).__init__()                self.config = config                self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')# Input normalization                self.input_norm = nn.BatchNorm1d(config.input_size)# Feature engineering layer                self.feature_projection = nn.Linear(config.input_size, config.hidden_size)# 2-layer LSTM                self.lstm = nn.LSTM(                input_size=config.hidden_size,                hidden_size=config.hidden_size,                num_layers=config.num_layers,                dropout=config.dropout if config.num_layers > 1 else 0,                batch_first=True,                bidirectional=False  # Causal for real-time prediction                )# Attention mechanisms                self.attention_layer = AttentionLayer(                config.hidden_size,                num_heads=config.attention_heads,                dropout=config.dropout                )                self.temporal_attention = TemporalAttention(                config.hidden_size,                temporal_window=20                )                self.financial_attention = FinancialAttention(                config.hidden_size,                market_features=config.input_size                )# Prediction heads                self.price_head = nn.Sequential(                nn.Linear(config.hidden_size, config.hidden_size // 2),                nn.ReLU(),                nn.Dropout(config.dropout),                nn.Linear(config.hidden_size // 2, config.prediction_horizon),                nn.Tanh()  # Normalized price changes                )                self.volatility_head = nn.Sequential(                nn.Linear(config.hidden_size, config.hidden_size // 4),                nn.ReLU(),                nn.Dropout(config.dropout),                nn.Linear(config.hidden_size // 4, config.prediction_horizon),                nn.Softplus()  # Positive volatility                )                self.confidence_head = nn.Sequential(                nn.Linear(config.hidden_size, config.hidden_size // 4),                nn.ReLU(),                nn.Linear(config.hidden_size // 4, config.prediction_horizon),                nn.Sigmoid()  # Confidence scores [0, 1]                )# Gary's DPI integration layer'                self.dpi_projection = nn.Linear(config.hidden_size, 1)# Antifragility enhancement                self.antifragile_gate = nn.Sequential(                nn.Linear(config.hidden_size, config.hidden_size // 2),                nn.Tanh(),                nn.Linear(config.hidden_size // 2, config.hidden_size),                nn.Sigmoid()                )# Initialize weights                self._init_weights()# Performance tracking                self.inference_times = []                self.prediction_accuracy = []    def _init_weights(self):
            """Initialize model weights using Xavier/He initialization."""        for name, param in self.named_parameters():
                if 'weight' in name:                    if len(param.shape) >= 2:                        nn.init.xavier_uniform_(param)                    else:                            nn.init.uniform_(param, -0.1, 0.1)                        elif 'bias' in name:                                nn.init.zeros_(param)    def forward(self,
        x: torch.Tensor,        market_context: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:            """Forward pass through LSTM predictor."        Args:
                x: Input time series [batch_size, seq_len, input_size]                market_context: Optional market context features                Returns:                    Dictionary containing predictions and intermediate outputs                    """                    start_time = time.time()                    batch_size, seq_len, input_size = x.shape# Input normalization and feature engineering                    x_norm = self.input_norm(x.view(-1, input_size)).view(batch_size, seq_len, input_size)                    features = torch.relu(self.feature_projection(x_norm))# LSTM forward pass                    lstm_out, (hidden, cell) = self.lstm(features)# Apply attention mechanisms                    attended_out, attention_weights = self.attention_layer(lstm_out)# Temporal attention for final representation                    temporal_context = self.temporal_attention(attended_out)# Financial market-aware attention if market context provided                    if market_context is not None:                        financial_context, financial_weights = self.financial_attention(                        attended_out, market_context                        )        # Combine temporal and financial contexts
                        final_context = (temporal_context + financial_context.mean(dim=1)) / 2                    else:                            final_context = temporal_context                            financial_weights = None# Antifragility enhancement (Taleb's principle)'                            if self.config.antifragility_weight > 0:                                antifragile_boost = self.antifragile_gate(final_context)                                final_context = final_context * (1 + self.config.antifragility_weight * antifragile_boost)# Generate predictions                                price_pred = self.price_head(final_context)                                volatility_pred = self.volatility_head(final_context)                                confidence_pred = self.confidence_head(final_context)# Gary's DPI calculation'                                dpi_score = torch.sigmoid(self.dpi_projection(final_context))# Track inference time                                inference_time = (time.time() - start_time) * 1000  # ms                                self.inference_times.append(inference_time)                                return {                                'price_prediction': price_pred,                                'volatility_prediction': volatility_pred,                                'confidence_scores': confidence_pred,                                'dpi_score': dpi_score,                                'attention_weights': attention_weights,                                'financial_weights': financial_weights,                                'final_context': final_context,                                'inference_time_ms': inference_time,                                'lstm_hidden': hidden,                                'lstm_cell': cell)    def predict_single(self,
        sequence: np.ndarray,        market_context: Optional[np.ndarray] = None) -> Dict[str, Any]:            """Single sequence prediction for real-time trading."        Optimized for <100ms inference time.
        Args:
                sequence: Time series data [seq_len, input_size]                market_context: Optional market context [seq_len, input_size]                Returns:                    Prediction dictionary with timing metrics                    """                    self.eval()                    with torch.no_grad():        # Convert to tensor and add batch dimension
                    pass  # Auto-fixed: empty block                    pass  # Auto-fixed: empty block                    pass  # Auto-fixed: empty block                    pass  # Auto-fixed: empty block                    pass  # Auto-fixed: empty block                    x = torch.FloatTensor(sequence).unsqueeze(0).to(self.device)                    if market_context is not None:                        market_context = torch.FloatTensor(market_context).unsqueeze(0).to(self.device)# Forward pass                        output = self.forward(x, market_context)# Convert to numpy for compatibility                        result = {                        'price_prediction': output['price_prediction'][0].cpu().numpy(),                        'volatility_prediction': output['volatility_prediction'][0].cpu().numpy(),                        'confidence_scores': output['confidence_scores'][0].cpu().numpy(),                        'dpi_score': output['dpi_score'][0].cpu().numpy(),                        'inference_time_ms': output['inference_time_ms'],                        'antifragile_enhanced': self.config.antifragility_weight > 0,                        'model_confidence': float(output['confidence_scores'][0].mean().cpu())                        }                        return result    def get_gary_dpi_factors(self, sequence: np.ndarray) -> Dict[str, float]:
            """Calculate Gary's DPI (Dynamic Position Intelligence) factors.'"        Args:
                sequence: Time series data [seq_len, input_size]                Returns:                    Dictionary of DPI factors                    """                    if not self.config.dpi_integration:                        return {}                        with torch.no_grad():        # Basic DPI calculations
                        pass  # Auto-fixed: empty block                        pass  # Auto-fixed: empty block                        pass  # Auto-fixed: empty block                        pass  # Auto-fixed: empty block                        pass  # Auto-fixed: empty block                        prices = sequence[:, 3]  # Close prices                        volumes = sequence[:, 4]  # Volumes# Price momentum (Gary's velocity factor)'                        price_momentum = np.mean(np.diff(prices[-10:]))  # Last 10 periods# Volume-weighted momentum                        volume_weight = volumes[-10:] / np.mean(volumes[-20:])                        weighted_momentum = price_momentum * np.mean(volume_weight)# Volatility factor                        volatility = np.std(prices[-20:])# DPI composite score                        dpi_composite = (weighted_momentum * 0.4 +                        price_momentum * 0.3 +                        (1 / (volatility + 1e-8)) * 0.3)                        return {                        'price_momentum': float(price_momentum),                        'weighted_momentum': float(weighted_momentum),                        'volatility_factor': float(volatility),                        'dpi_composite': float(dpi_composite),                        'volume_pressure': float(np.mean(volume_weight)),                        'trend_strength': float(abs(price_momentum) / (volatility + 1e-8))                        }    def apply_taleb_antifragility(self,
        predictions: Dict[str, np.ndarray],        market_stress: float = 0.0) -> Dict[str, np.ndarray]:        \"\"\"Apply Taleb's antifragility principles to predictions.'
        Enhances predictions during market stress periods.
        Args:
                predictions: Model predictions                market_stress: Market stress indicator [0, 1]                Returns:                    Antifragility-enhanced predictions                    \"\"\"                    if not self.config.antifragility_weight or market_stress == 0:                        return predictions                        enhanced_predictions = predictions.copy()# Antifragile enhancement during stress                        stress_multiplier = 1 + (market_stress * self.config.antifragility_weight)# Increase volatility predictions during stress (opportunity detection)                        enhanced_predictions['volatility_prediction'] *= stress_multiplier# Adjust confidence based on antifragile principles# Higher confidence in predictions during stress (contrarian approach)                        enhanced_predictions['confidence_scores'] = np.minimum(            enhanced_predictions['confidence_scores'] * stress_multiplier,            1.0        )                # Add antifragility score        enhanced_predictions['antifragility_score'] = market_stress * stress_multiplier                return enhanced_predictions        def optimize_for_inference(self):        \"\"\"Optimize model for <100ms inference.                Applies various optimization techniques for production deployment.        \"\"\"        # Compile model for faster inference        if torch.__version__ >= \"2.0.0\":            self = torch.compile(self, mode='max-autotune')                # Enable optimized attention        if hasattr(torch.backends, 'cuda'):            torch.backends.cuda.enable_flash_sdp(True)                # Set to eval mode and disable gradients        self.eval()        for param in self.parameters():            param.requires_grad = False                print(f\"Model optimized for inference. Target: <100ms\")            def get_performance_metrics(self) -> Dict[str, float]:        \"\"\"Get model performance metrics.                Returns:            Performance statistics        \"\"\"        if not self.inference_times:            return {\"status\": \"No inference data available\"}                return {            'avg_inference_time_ms': np.mean(self.inference_times[-100:]),  # Last 100            'max_inference_time_ms': np.max(self.inference_times[-100:]),            'min_inference_time_ms': np.min(self.inference_times[-100:]),            'inference_target_met': np.mean(self.inference_times[-100:]) < 100,            'total_predictions': len(self.inference_times),            'model_parameters': sum(p.numel() for p in self.parameters()),            'memory_usage_mb': torch.cuda.memory_allocated() / 1024 / 1024 if torch.cuda.is_available() else 0)class LSTMTrainer:    \"\"\"Training utilities for LSTM predictor.\"\"\"        def __init__(self, model: LSTMPredictor, config: LSTMConfig):        self.model = model        self.config = config        self.optimizer = torch.optim.AdamW(            model.parameters(),            lr=config.learning_rate,            weight_decay=config.weight_decay        )        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(            self.optimizer, mode='min', patience=5, factor=0.7        )            def compute_loss(self, predictions: Dict[str, torch.Tensor], targets: Dict[str, torch.Tensor]) -> torch.Tensor:        \"\"\"Compute multi-component loss function.\"\"\"        # Price prediction loss (MSE)        price_loss = nn.MSELoss()(predictions['price_prediction'], targets['price'])                # Volatility prediction loss        vol_loss = nn.MSELoss()(predictions['volatility_prediction'], targets['volatility'])                # DPI integration loss (if available)        dpi_loss = 0        if 'dpi_target' in targets:            dpi_loss = nn.MSELoss()(predictions['dpi_score'], targets['dpi_target'])                # Combined loss        total_loss = price_loss + 0.3 * vol_loss + 0.2 * dpi_loss                return total_loss        def train_epoch(self, dataloader) -> float:        \"\"\"Train model for one epoch.\"\"\"        self.model.train()        total_loss = 0                for batch in dataloader:            self.optimizer.zero_grad()                        # Forward pass            outputs = self.model(batch['sequences'], batch.get('market_context'))                        # Compute loss            loss = self.compute_loss(outputs, batch['targets'])                        # Backward pass            loss.backward()                        # Gradient clipping            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)                        self.optimizer.step()            total_loss += loss.item()                return total_loss / len(dataloader)# Factory function for easy model creationdef create_lstm_predictor(    sequence_length: int = 60,    hidden_size: int = 128,    enable_dpi: bool = True,    antifragility_weight: float = 0.15) -> LSTMPredictor:    \"\"\"Create LSTM predictor with GaryTaleb integration.        Args:        sequence_length: Input sequence length        hidden_size: LSTM hidden size        enable_dpi: Enable Gary's DPI calculations\n        antifragility_weight: Taleb's antifragility factor            Returns:        Configured LSTM predictor    \"\"\"    config = LSTMConfig(        sequence_length=sequence_length,        hidden_size=hidden_size,        dpi_integration=enable_dpi,        antifragility_weight=antifragility_weight    )        model = LSTMPredictor(config)    model.optimize_for_inference(}        return model""}